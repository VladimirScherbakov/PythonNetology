{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. \n",
    "\n",
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем парсить страницу со свежеми новостям на [habr.com/ru/all/](https://habr.com/ru/all/).\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "`KEYWORDS = ['python', 'парсинг']`\n",
    "\n",
    " Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы). \n",
    " \n",
    "В итоге должен формироваться датафрейм со столбцами: <дата> - <заголовок> - <ссылка>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>header</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>сегодня в 19:50</td>\n",
       "      <td>FOSS News №28 – дайджест новостей свободного и...</td>\n",
       "      <td>https://habr.com/ru/post/514434/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>сегодня в 15:43</td>\n",
       "      <td>Как не потерять ход времени, работая за компью...</td>\n",
       "      <td>https://habr.com/ru/post/514414/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>сегодня в 08:21</td>\n",
       "      <td>Мониторинг демон на Asyncio + Dependency Injec...</td>\n",
       "      <td>https://habr.com/ru/post/514384/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>сегодня в 08:21</td>\n",
       "      <td>Мониторинг демон на Asyncio + Dependency Injec...</td>\n",
       "      <td>https://habr.com/ru/post/514384/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              data                                             header  \\\n",
       "0  сегодня в 19:50  FOSS News №28 – дайджест новостей свободного и...   \n",
       "1  сегодня в 15:43  Как не потерять ход времени, работая за компью...   \n",
       "2  сегодня в 08:21  Мониторинг демон на Asyncio + Dependency Injec...   \n",
       "3  сегодня в 08:21  Мониторинг демон на Asyncio + Dependency Injec...   \n",
       "\n",
       "                                url  \n",
       "0  https://habr.com/ru/post/514434/  \n",
       "1  https://habr.com/ru/post/514414/  \n",
       "2  https://habr.com/ru/post/514384/  \n",
       "3  https://habr.com/ru/post/514384/  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = ['python', 'парсинг']\n",
    "\n",
    "list_date, list_header, list_url = [], [], []\n",
    "res_dict = {'data': list_date,\n",
    "         'header': list_header,\n",
    "         'url': list_url}\n",
    "\n",
    "url = 'https://habr.com/ru/all/'\n",
    "web_page = requests.get(url)\n",
    "\n",
    "if web_page.status_code != 200:\n",
    "    print(f'Страница {url} недоступна.')\n",
    "    \n",
    "else:\n",
    "    soup = BeautifulSoup(web_page.text, 'html.parser') # Создание объекта стартовой страницы\n",
    "    start_page = soup.find('div', class_='content_left js-content_left') # Скрапинг стартовой страницы\n",
    "    \n",
    "    article_url = start_page.find_all('a', class_='post__title_link') # Получаем все ссылки на новости со стартовой страницы\n",
    "    list_article_url = list() # Список ссылок\n",
    "    for url in article_url:\n",
    "        list_article_url.append(url.get('href'))\n",
    "    \n",
    "    for article in list_article_url: # Проходимся по каждой статье\n",
    "        article_page = requests.get(article)\n",
    "        soup = BeautifulSoup(article_page.text, 'html.parser') # Создание объекта страницы с новостью\n",
    "        \n",
    "        for keyword in keywords: # Проверяем наличие ключевых слов в тексте статьи\n",
    "            article_text = soup.find('div', class_='post__text post__text-html post__text_v1').get_text()\n",
    "            \n",
    "            if keyword in article_text.lower(): # Если слово есть, то добавляем в списки\n",
    "                list_date.append(soup.find('span', class_='post__time').get_text()) # получаем дату\n",
    "                list_header.append(soup.find('span', class_='post__title-text').get_text()) # получаем дату\n",
    "                list_url.append(article)\n",
    "    \n",
    "    res_dict['data'] = list_date\n",
    "    res_dict['header'] = list_header\n",
    "    res_dict['url'] = list_url\n",
    "\n",
    "\n",
    "res_df = pd.DataFrame(res_dict)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.\n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: <дата> - <заголовок> - <ссылка> - <текст статьи>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса [Avast Hack Ckeck](https://www.avast.com/hackcheck/).\n",
    "Список email-ов задаем переменной в начале кода:  \n",
    "`EMAIL = [xxx@x.ru, yyy@y.com]`\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>date</th>\n",
       "      <th>source</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ivan__12</td>\n",
       "      <td>2020-07-23 03:00:00</td>\n",
       "      <td>LiveAuctioneers</td>\n",
       "      <td>In June 2020, the online marketplace LiveAucti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>superivan123</td>\n",
       "      <td>2019-05-23 03:00:00</td>\n",
       "      <td>LiveJournal</td>\n",
       "      <td>In 2017, social network LiveJournal's database...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>luka68</td>\n",
       "      <td>2019-05-23 03:00:00</td>\n",
       "      <td>LiveJournal</td>\n",
       "      <td>In 2017, social network LiveJournal's database...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ghyid</td>\n",
       "      <td>2019-05-23 03:00:00</td>\n",
       "      <td>LiveJournal</td>\n",
       "      <td>In 2017, social network LiveJournal's database...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thuyr</td>\n",
       "      <td>2019-05-23 03:00:00</td>\n",
       "      <td>LiveJournal</td>\n",
       "      <td>In 2017, social network LiveJournal's database...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>jhon@google.com</td>\n",
       "      <td>2017-06-01 03:00:00</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>jhon@google.com</td>\n",
       "      <td>2019-02-06 03:00:00</td>\n",
       "      <td>AP MYR and Zabugor Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>jhon@google.com</td>\n",
       "      <td>2020-01-09 03:00:00</td>\n",
       "      <td>Sensitive Source</td>\n",
       "      <td>This source has been marked as sensitive due t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>earl112</td>\n",
       "      <td>2016-10-20 03:00:00</td>\n",
       "      <td>Neopets</td>\n",
       "      <td>In May 2016, it was reported that approximatel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>jhon@google.com</td>\n",
       "      <td>2019-01-25 03:00:00</td>\n",
       "      <td>Collection #1 Combo List</td>\n",
       "      <td>On January 7, 2019, an online user named Sanix...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              email                date                         source  \\\n",
       "0          ivan__12 2020-07-23 03:00:00                LiveAuctioneers   \n",
       "1      superivan123 2019-05-23 03:00:00                    LiveJournal   \n",
       "2            luka68 2019-05-23 03:00:00                    LiveJournal   \n",
       "3             ghyid 2019-05-23 03:00:00                    LiveJournal   \n",
       "4             thuyr 2019-05-23 03:00:00                    LiveJournal   \n",
       "..              ...                 ...                            ...   \n",
       "74  jhon@google.com 2017-06-01 03:00:00               Sensitive Source   \n",
       "75  jhon@google.com 2019-02-06 03:00:00  AP MYR and Zabugor Combo List   \n",
       "76  jhon@google.com 2020-01-09 03:00:00               Sensitive Source   \n",
       "77          earl112 2016-10-20 03:00:00                        Neopets   \n",
       "78  jhon@google.com 2019-01-25 03:00:00       Collection #1 Combo List   \n",
       "\n",
       "                                          description  \n",
       "0   In June 2020, the online marketplace LiveAucti...  \n",
       "1   In 2017, social network LiveJournal's database...  \n",
       "2   In 2017, social network LiveJournal's database...  \n",
       "3   In 2017, social network LiveJournal's database...  \n",
       "4   In 2017, social network LiveJournal's database...  \n",
       "..                                                ...  \n",
       "74  This source has been marked as sensitive due t...  \n",
       "75  On January 7, 2019, an online user named Sanix...  \n",
       "76  This source has been marked as sensitive due t...  \n",
       "77  In May 2016, it was reported that approximatel...  \n",
       "78  On January 7, 2019, an online user named Sanix...  \n",
       "\n",
       "[79 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import datetime as dt\n",
    "\n",
    "emails = ['ivan@mail.ru', 'jhon@google.com']\n",
    "\n",
    "def checking_email (email):\n",
    "    url = 'https://digibody.avast.com/v1/web/leaks'\n",
    "    data = {'email': email}\n",
    "    res_page = requests.post(url, data=json.dumps(data))\n",
    "    return res_page.json()\n",
    "\n",
    "\n",
    "list_email, list_date, list_source, list_description = [], [], [], []\n",
    "res_check_dict = {'email': list_email,\n",
    "                  'date': list_date,\n",
    "                  'source': list_source,\n",
    "                  'description': list_description}\n",
    "\n",
    "for email in emails:\n",
    "    result = checking_email(email)\n",
    "    \n",
    "    for element in result['value']:\n",
    "        list_email.append(element['username'])\n",
    "        list_date.append(dt.datetime.fromtimestamp(element['leak_info']['date']/1000))\n",
    "        list_source.append(element['leak_info']['title'])\n",
    "        list_description.append(element['leak_info']['description'])\n",
    "\n",
    "res_check_dict['email'] = list_email\n",
    "res_check_dict['date'] = list_date\n",
    "res_check_dict['source'] = list_source\n",
    "res_check_dict['description'] = list_description\n",
    "    \n",
    "res_check_df = pd.DataFrame(res_check_dict)\n",
    "res_check_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.  \n",
    "Документация к API VK: https://vk.com/dev/methods\n",
    ", вам поможет метод [wall.get](https://vk.com/dev/wall.get)```\n",
    "GROUP = 'netology'\n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ\n",
    "```\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <дата поста> - <текст поста>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРИМЕЧАНИЕ\n",
    "Домашнее задание сдается ссылкой на репозиторий [GitHub](https://github.com/).\n",
    "Не сможем проверить или помочь, если вы пришлете:\n",
    "- файлы;\n",
    "- архивы;\n",
    "- скриншоты кода.\n",
    "\n",
    "Все обсуждения и консультации по выполнению домашнего задания ведутся только на соответствующем канале в slack.\n",
    "\n",
    "##### Как правильно задавать вопросы аспирантам, преподавателям и коллегам?\n",
    "Прежде чем задать вопрос необходимо попробовать найти ответ самому в интернете. Навык самостоятельного поиска информации – один из важнейших, и каждый практикующий специалист любого уровня это делает каждый день.\n",
    "\n",
    "Любой вопрос должен быть сформулирован по алгоритму:  \n",
    "1) Что я делаю?  \n",
    "2) Какого результата я ожидаю?  \n",
    "3) Как фактический результат отличается от ожидаемого?  \n",
    "4) Что я уже попробовал сделать, чтобы исправить проблему?  \n",
    "\n",
    "По возможности, прикрепляйте к вопросу скриншоты, либо ссылки на код. Оставляйте только проблемный и воспроизводимый участок кода, все решение выкладывать не допускается.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
